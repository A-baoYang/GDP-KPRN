{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ratings_re = open(\"ratings_re.csv\").readlines()\n",
    "file_triples_idx = open(\"triples_idx.txt\").readlines()\n",
    "\n",
    "file_moviesIdx = open(\"moviesIdx.txt\").readlines() \n",
    "file_types = open(\"types.txt\").readlines() \n",
    "file_entities = open(\"entities.txt\").readlines()\n",
    "file_relations = open(\"relations.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entity id -> name mapping\n",
    "entity_id_to_name = {}\n",
    "for line in file_moviesIdx:\n",
    "    movie_title, entity_id = line.strip().split()\n",
    "    entity_id_to_name[entity_id] = movie_title\n",
    "    \n",
    "for line in file_entities:\n",
    "    entity_name, entity_id = line.strip().split()\n",
    "    entity_id_to_name[entity_id] = entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create movie title -> entity type mapping and list of entity for each type\n",
    "\n",
    "movie_title_to_entity_type = {}\n",
    "entity_list_with_type = {}\n",
    "\n",
    "for line in file_types:\n",
    "    \n",
    "    # movie title -> entity type\n",
    "    entity, entity_type = line.strip().split('\\t')\n",
    "    movie_title_to_entity_type[entity] = entity_type\n",
    "    \n",
    "    # entity for each type\n",
    "    if entity_type not in entity_list_with_type:\n",
    "        entity_list_with_type[entity_type] = []\n",
    "    \n",
    "    entity_list_with_type[entity_type].append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relation id to name mapping\n",
    "relation_id_to_name = {}\n",
    "for line in file_relations:\n",
    "    relation_name, relation_id = line.strip().split()\n",
    "    relation_id = int(relation_id)\n",
    "    relation_id += 200000\n",
    "    \n",
    "    # last 2 relation : spouse and relative has no inverse\n",
    "    if relation_id < 200023:\n",
    "        relation_id_to_name[str(relation_id + 1)] = relation_name + \"_inverse\"\n",
    "    \n",
    "    relation_id_to_name[str(relation_id)] = relation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_entity_id_padding = 500000\n",
    "relation_rated_good_by_id = '200026'\n",
    "relation_given_good_rating_id = '200027'\n",
    "good_movie_rating_threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kg_path():\n",
    "\n",
    "    ### Create entity_id path in knowledge graph\n",
    "    kg_path = {}\n",
    "    for line in file_triples_idx:\n",
    "\n",
    "        head, relation, tail = line.strip().split()\n",
    "        if head not in kg_path:\n",
    "            kg_path[head] = {}\n",
    "\n",
    "        if relation not in kg_path[head]:\n",
    "            kg_path[head][relation] = []\n",
    "\n",
    "        kg_path[head][relation].append(tail)\n",
    "        \n",
    "    ### Insert user rated relation into knowledge graph (collab filtering effect)\n",
    "    for line in tqdm(file_ratings_re):\n",
    "        user_id, movie_id, rating = line.split(',')[:3]\n",
    "        user_entity_id = str(user_entity_id_padding + int(user_id))\n",
    "\n",
    "        # skip if movie is bad\n",
    "        if float(rating) < good_movie_rating_threshold :\n",
    "            continue\n",
    "\n",
    "        # Add given-good-rating for each user\n",
    "        if user_entity_id not in kg_path:\n",
    "            kg_path[user_entity_id] = {}\n",
    "            kg_path[user_entity_id][relation_given_good_rating_id] = []\n",
    "\n",
    "        # Add rated-good-by for the movie\n",
    "        if relation_rated_good_by_id not in kg_path[movie_id]:\n",
    "            kg_path[movie_id][relation_rated_good_by_id] = []\n",
    "\n",
    "        kg_path[user_entity_id][relation_given_good_rating_id].append(movie_id)\n",
    "        kg_path[movie_id][relation_rated_good_by_id].append(user_entity_id)\n",
    "        \n",
    "    pickle.dump(kg_path, open(\"cache_kg_path\", \"wb\"))\n",
    "    return kg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kg_path():\n",
    "    try:\n",
    "        kg_path = pickle.load(open(\"cache_kg_path\", \"rb\"))\n",
    "    except:\n",
    "        kg_path = create_kg_path()\n",
    "    finally:\n",
    "        return kg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_path = load_kg_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "def generate_path_from_entity(entity_id, depth, n_sample_for_each_relation=2):\n",
    "    \n",
    "    generated_paths = []\n",
    "    \n",
    "    for relation in kg_path[entity_id]:\n",
    "        tails = kg_path[entity_id][relation]\n",
    "        \n",
    "        sample_idx = randint(0, len(tails), n_sample_for_each_relation)\n",
    "        sampled_tails = [tails[x] for x in sample_idx]\n",
    "        \n",
    "        for sampled_tail in sampled_tails:\n",
    "            \n",
    "            # RECURSE until last layer - 1 is enough\n",
    "            if depth > 2 :\n",
    "                future_paths = generate_path_from_entity(sampled_tail, depth-1, n_sample_for_each_relation)\n",
    "                generated_paths += [\"{} {} {}\".format(relation, sampled_tail, x) for x in future_paths]\n",
    "                \n",
    "            else:\n",
    "                generated_paths.append(\"{} {}\".format(relation, sampled_tail))\n",
    "    \n",
    "    return generated_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list_to_file(list_obj, filename):\n",
    "    with open(filename, 'w') as writer:\n",
    "        for item in list_obj:\n",
    "            \n",
    "            if \"\\n\" in item:\n",
    "                writer.write(item)\n",
    "            else:\n",
    "                writer.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_user_rated_potential_movie(user_id, potential_id):\n",
    "    return potential_id in kg_path[user_id][relation_given_good_rating_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Create path from user - movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random_sample\n",
    "\n",
    "def split_dataset_positive_negative(path_dataset, sampling_negative_ratio=0.15):\n",
    "    \n",
    "    positive_dataset = []\n",
    "    negative_dataset = []\n",
    "    \n",
    "    for line in (path_dataset):\n",
    "        split = line.split()\n",
    "\n",
    "        user_id = split[0]\n",
    "        potential_movie = split[-1]\n",
    "\n",
    "        if is_user_rated_potential_movie(user_id, potential_movie) :\n",
    "            positive_dataset.append(line.strip() + \" 1\")\n",
    "        else:\n",
    "            if random_sample() < sampling_negative_ratio:\n",
    "                negative_dataset.append(line.strip() + \" 0\")\n",
    "    \n",
    "    positive_dataset = sorted(positive_dataset)\n",
    "    negative_dataset = sorted(negative_dataset)\n",
    "    \n",
    "    return positive_dataset, negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "n_sample_for_each_relation = 2\n",
    "batch_count = 0\n",
    "path_depth = 3\n",
    "\n",
    "generated_paths = []\n",
    "for line in tqdm(file_ratings_re):\n",
    "    \n",
    "    # Save as batch\n",
    "    if len(generated_paths) > 5000000:\n",
    "        \n",
    "        generated_paths = list(dict.fromkeys(generated_paths))        \n",
    "        positive_dataset, negative_dataset = split_dataset_positive_negative(generated_paths)\n",
    "            \n",
    "        save_list_to_file(positive_dataset, \"positive_path_{}.txt\".format(batch_count))\n",
    "        save_list_to_file(negative_dataset, \"negative_path_{}.txt\".format(batch_count))\n",
    "        print(\"saved batch {}\".format(batch_count))\n",
    "        \n",
    "        batch_count += 1\n",
    "        generated_paths = []\n",
    "    \n",
    "    start_user_id, start_movie_id, rating = line.split(',')[:3]\n",
    "    start_user_entity_id = str(user_entity_id_padding + int(start_user_id))\n",
    "    \n",
    "    # skip if movie is bad\n",
    "    if float(rating) < good_movie_rating_threshold :\n",
    "        continue\n",
    "        \n",
    "    future_paths = generate_path_from_entity(start_movie_id, path_depth)\n",
    "    generated_paths += [\"{} {} {} {}\".format(start_user_entity_id, relation_given_good_rating_id, start_movie_id, x) for x in future_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Reasoning part (extra)\n",
    "\n",
    "Reading path as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_paths = open(\"negative_path_1.txt\", 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_entity_name(entity_id):\n",
    "    \n",
    "    if entity_id in entity_id_to_name:\n",
    "        return entity_id_to_name[entity_id]\n",
    "    elif entity_id in relation_id_to_name:\n",
    "        return relation_id_to_name[entity_id]\n",
    "    else:\n",
    "        return \"user_{}\".format(entity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reasoning_path = []\n",
    "for line in tqdm(sample_paths):\n",
    "    string_line = \" -> \".join([get_entity_name(x) for x in line.split()[:-1]])\n",
    "    reasoning_path.append(string_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reasoning_path[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare other vocabulary things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity = [x.strip().split() for x in file_moviesIdx]\n",
    "all_entity += [x.strip().split() for x in file_entities]\n",
    "all_entity = [\"\\t\".join(x) for x in all_entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list_to_file(all_entity, \"all_entity_id.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation = sorted(relation_id_to_name.items()) # sorted by key, return a list of tuples\n",
    "all_relation = [\"{}\\t{}\".format(x[1], x[0]) for x in relation] # unpack a list of pairs into two tuples\n",
    "\n",
    "all_relation += [\n",
    "    \"#UNK_RELATION\\t200028\",\n",
    "    \"#PAD_TOKEN\\t200029\",\n",
    "    \"#END_RELATION\\t200030\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list_to_file(all_relation, \"all_relation_id.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All entity type (including movie alr)\n",
    "all_types = [x.strip() for x in file_types]\n",
    "\n",
    "# All user\n",
    "n_users = int(file_ratings_re[-1].split(',')[0])\n",
    "all_types += [\"u{}\\tUser\".format(i) for i in range(1, n_users + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list_to_file(all_types, \"entity_to_type.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_type = [\n",
    "    \"Category\",\n",
    "    \"Company\",\n",
    "    \"Country\",\n",
    "    \"Genre\",\n",
    "    \"Movie\",\n",
    "    \"Person\",\n",
    "    \"User\",\n",
    "    \n",
    "    \"#PAD_TOKEN\",\n",
    "    \"#UNK_ENTITY_TYPE\",\n",
    "]\n",
    "\n",
    "entity_type_to_id = {}\n",
    "entity_type_with_id = []\n",
    "\n",
    "for i in range(0, len(list_of_type)):\n",
    "    entity_type = list_of_type[i]\n",
    "    entity_type_to_id[entity_type] = i\n",
    "    entity_type_with_id.append(\"{}\\t{}\".format(entity_type, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list_to_file(entity_type_with_id, \"entity_type_id.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_from_entity_id(entity_id):\n",
    "    \n",
    "    # user\n",
    "    if int(entity_id) > user_entity_id_padding:\n",
    "        return \"User\"\n",
    "    elif entity_id_to_name[entity_id] in movie_title_to_entity_type:\n",
    "        return movie_title_to_entity_type[entity_id_to_name[entity_id]]\n",
    "    else:\n",
    "        return \"#UNK_ENTITY_TYPE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "END_RELATION = 200030\n",
    "BATCH_COUNT = 72\n",
    "\n",
    "def create_own_format():\n",
    "    \n",
    "    for p in ['positive', 'negative']:\n",
    "        for i in tqdm(range(0, BATCH_COUNT)):\n",
    "\n",
    "            sample_paths = open(\"{}_path_{}.txt\".format(p, i), 'r').readlines()\n",
    "\n",
    "            dataset = []\n",
    "            for line in sample_paths:\n",
    "                e1, r1, e2, r2, e3, r3, e4, label = line.strip().split()\n",
    "\n",
    "                t1 = entity_type_to_id[get_type_from_entity_id(e1)]\n",
    "                t2 = entity_type_to_id[get_type_from_entity_id(e2)]\n",
    "                t3 = entity_type_to_id[get_type_from_entity_id(e3)]\n",
    "                t4 = entity_type_to_id[get_type_from_entity_id(e4)]\n",
    "\n",
    "                r4 = END_RELATION\n",
    "\n",
    "                output = [\n",
    "                    \"{} {} {}\".format(e1, t1, r1),\n",
    "                    \"{} {} {}\".format(e2, t2, r2),\n",
    "                    \"{} {} {}\".format(e3, t3, r3),\n",
    "                    \"{} {} {}\".format(e4, t4, r4),\n",
    "                    label\n",
    "                ]\n",
    "\n",
    "                output = \"#\".join(output)\n",
    "                dataset.append(output)\n",
    "        \n",
    "            save_list_to_file(dataset, \"new_{}_path_{}.txt\".format(p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_own_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for p in ['positive', 'negative']:\n",
    "    for i in range(0, BATCH_COUNT):\n",
    "        try:\n",
    "            os.remove(\"{}_path_{}.txt\".format(p, i))\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "732px",
    "left": "1546px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
