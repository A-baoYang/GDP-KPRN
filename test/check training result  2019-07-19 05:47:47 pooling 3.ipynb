{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **Test KPRN Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CODE = \"2019-07-19 05:47:47\"\n",
    "MODEL_DIR = \"../logs/{}\".format(TEST_CODE)\n",
    "CHOSEN_EPOCH = 5\n",
    "\n",
    "MAX_SEED_NUM = 3\n",
    "MAX_RELATION_NUM = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = sorted(os.listdir(MODEL_DIR))\n",
    "choosen_weight = \"{}/{}\".format(MODEL_DIR, trained_weights[CHOSEN_EPOCH - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 08:49:10.539453 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 08:49:10.545511 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 08:49:10.572175 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 08:49:10.695865 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0801 08:49:10.708605 140241513215744 deprecation.py:506] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0801 08:49:11.120377 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0801 08:49:12.073914 140241513215744 deprecation_wrapper.py:119] From /home/jessinra/.local/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0801 08:49:12.086633 140241513215744 deprecation.py:323] From /home/jessinra/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(choosen_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ratings_re = open(\"../data/ratings_re.csv\").readlines()\n",
    "file_triples_idx = open(\"../data/triples_idx.txt\").readlines()\n",
    "file_moviesIdx = open(\"../data/moviesIdx.txt\").readlines()\n",
    "file_types = open(\"../data/types.txt\").readlines()\n",
    "file_entities = open(\"../data/entities.txt\").readlines()\n",
    "file_relations = open(\"../data/relations.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_entity_to_name():\n",
    "\n",
    "    entity_id_to_name = {}\n",
    "    for line in file_moviesIdx:\n",
    "        movie_title, entity_id = line.strip().split()\n",
    "        entity_id_to_name[entity_id] = movie_title\n",
    "\n",
    "    for line in file_entities:\n",
    "        entity_name, entity_id = line.strip().split()\n",
    "        entity_id_to_name[entity_id] = entity_name\n",
    "\n",
    "    return entity_id_to_name\n",
    "\n",
    "def _get_movie_title_to_entity_type():\n",
    "\n",
    "    movie_title_to_entity_type = {}\n",
    "    for line in file_types:\n",
    "\n",
    "        entity, entity_type = line.strip().split('\\t')\n",
    "        movie_title_to_entity_type[entity] = entity_type\n",
    "\n",
    "    return movie_title_to_entity_type\n",
    "\n",
    "def _get_entity_list_with_type():\n",
    "\n",
    "    entity_list_with_type = {}\n",
    "    for line in file_types:\n",
    "\n",
    "        entity, entity_type = line.strip().split('\\t')\n",
    "        if entity_type not in entity_list_with_type:\n",
    "            entity_list_with_type[entity_type] = []\n",
    "        entity_list_with_type[entity_type].append(entity)\n",
    "\n",
    "    return entity_list_with_type\n",
    "\n",
    "REL_ID_END = '200030'\n",
    "def _get_relation_to_name():\n",
    "\n",
    "    # Create relation id to name mapping\n",
    "    relation_id_to_name = {}\n",
    "    for line in file_relations:\n",
    "        relation_name, relation_id = line.strip().split()\n",
    "        relation_id = int(relation_id)\n",
    "        relation_id += 200000\n",
    "\n",
    "        # last 2 relation : spouse and relative has no inverse\n",
    "        if relation_id < 200023:\n",
    "            relation_id_to_name[str(relation_id + 1)] = relation_name + \"_inverse\"\n",
    "\n",
    "        relation_id_to_name[str(relation_id)] = relation_name\n",
    "\n",
    "    relation_id_to_name[REL_ID_END] = \"END\"\n",
    "    return relation_id_to_name\n",
    "\n",
    "def _get_entity_type_to_id():\n",
    "\n",
    "    list_of_type = [\n",
    "        \"Category\",\n",
    "        \"Company\",\n",
    "        \"Country\",\n",
    "        \"Genre\",\n",
    "        \"Movie\",\n",
    "        \"Person\",\n",
    "        \"User\",\n",
    "        \"#PAD_TOKEN\",\n",
    "        \"#UNK_ENTITY_TYPE\",\n",
    "    ]\n",
    "\n",
    "    entity_type_to_id = {list_of_type[i]: i for i in range(0, len(list_of_type))}\n",
    "    return entity_type_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_to_entity_type = _get_movie_title_to_entity_type()\n",
    "entity_list_with_type = _get_entity_list_with_type()\n",
    "entity_id_to_name = _get_entity_to_name()\n",
    "relation_id_to_name = _get_relation_to_name()\n",
    "entity_type_to_id = _get_entity_type_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ENTITY_ID_PADDING = 500000\n",
    "def get_type_from_entity_id(entity_id):\n",
    "    # user\n",
    "    if int(entity_id) > USER_ENTITY_ID_PADDING:\n",
    "        return \"User\"\n",
    "    elif entity_id_to_name[entity_id] in movie_title_to_entity_type:\n",
    "        return movie_title_to_entity_type[entity_id_to_name[entity_id]]\n",
    "    else:\n",
    "        return \"#UNK_ENTITY_TYPE\"\n",
    "    \n",
    "def path_to_string(paths):\n",
    "    string_paths = []\n",
    "    for path in paths:\n",
    "\n",
    "        entity_string = []\n",
    "        for entity in path.split():\n",
    "            entity_string.append(get_entity_name(str(entity)))\n",
    "        entity_string = \" -> \".join(entity_string)\n",
    "\n",
    "        string_paths.append(entity_string)\n",
    "\n",
    "    return string_paths\n",
    "\n",
    "def get_entity_name(entity_id):\n",
    "\n",
    "    if entity_id in entity_id_to_name:\n",
    "        return entity_id_to_name[entity_id]\n",
    "    elif entity_id in relation_id_to_name:\n",
    "        return relation_id_to_name[entity_id]\n",
    "    else:\n",
    "        return \"user_{}\".format(entity_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Load KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KG from cache\n",
    "kg_path = pickle.load(open(\"../data/cache_kg_path\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Prepare path for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRREGULAR_RELATION = ['200024', '200025']\n",
    "NUM_OF_ITEMS = len(file_moviesIdx)\n",
    "\n",
    "def _generate_path_from_entity_to_all_others(entity_id, keep_relation_ratio=0.5, max_relation_num=30, max_entity_per_relation=1):\n",
    "\n",
    "    generated_paths = []\n",
    "\n",
    "    # Get direct relation attached to entity1\n",
    "    r1 = kg_path[entity_id]\n",
    "\n",
    "    # List all possible item-entities\n",
    "    all_item_entities = [str(x) for x in range(0, NUM_OF_ITEMS)]\n",
    "    for e2_id in all_item_entities:\n",
    "\n",
    "        # Skip if e1 == e2 (path to itself)\n",
    "        if e2_id == entity_id:\n",
    "            continue\n",
    "\n",
    "        # Get relations attached to entity2\n",
    "        r2 = kg_path[e2_id]\n",
    "\n",
    "        # Downsample intersect relation\n",
    "        intersect_relations = list(set(r1.keys()).intersection(set(r2.keys())))\n",
    "        if len(intersect_relations) < max_relation_num:\n",
    "            n_intersect_relation = len(intersect_relations)\n",
    "        else:\n",
    "            n_intersect_relation = max(max_relation_num, int(len(intersect_relations) * keep_relation_ratio))\n",
    "\n",
    "        # Find intersect between relation 1 and relation 2\n",
    "        np.random.shuffle(intersect_relations)\n",
    "        for relation in intersect_relations[:n_intersect_relation]:\n",
    "\n",
    "            # Find entities attached to relation (non-item entities)\n",
    "            intersect_entity = list(set(r1[relation]).intersection(set(r2[relation])))\n",
    "\n",
    "            # Down sample intersecting entities\n",
    "            np.random.shuffle(intersect_entity)\n",
    "            for mid_entity in intersect_entity[:max_entity_per_relation]:\n",
    "\n",
    "                # Format path and add to result\n",
    "                inverse_relation = relation if (relation in IRREGULAR_RELATION) else str(int(relation) + 1)\n",
    "                path = \"{} {} {} {} {}\".format(entity_id, relation, mid_entity, inverse_relation, e2_id)\n",
    "                generated_paths.append(path)\n",
    "\n",
    "    return generated_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_ID_GIVEN_GOOD_RATING = '200027'\n",
    "def _generate_all_path_from_user(user_id, max_seed_num=10, max_seed_ratio=0.2):\n",
    "\n",
    "    # List down all user interacted items\n",
    "    user_interacted_items = []\n",
    "    for relation in kg_path[user_id]:\n",
    "        user_interacted_items += kg_path[user_id][relation]\n",
    "    user_interacted_items = sorted(set(user_interacted_items))\n",
    "\n",
    "    # Downsample seeds (item interacted)\n",
    "    if len(user_interacted_items) < max_seed_num:\n",
    "        n_seed = len(user_interacted_items)\n",
    "    else:\n",
    "        n_seed = max(max_seed_num, int(len(user_interacted_items) * max_seed_ratio))\n",
    "    np.random.shuffle(user_interacted_items)\n",
    "    user_interacted_items = user_interacted_items[:n_seed]\n",
    "\n",
    "    # ====== Threading ======\n",
    "    user_paths = []\n",
    "    threads = []\n",
    "    for i in range(0, n_seed):\n",
    "\n",
    "        # Split items id equally\n",
    "        thread_items = user_interacted_items[i::n_seed]\n",
    "        thread = threading.Thread(target=_run_thread, args=(i, thread_items, user_paths))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Wait for all thread to finish\n",
    "    for i in range(0, n_seed):\n",
    "        threads[i].join()\n",
    "\n",
    "    # Reformat : add user id and 'REL_ID_GIVEN_GOOD_RATING'\n",
    "    user_paths = [\"{} {} {}\".format(user_id, REL_ID_GIVEN_GOOD_RATING, x) for x in user_paths]\n",
    "    return user_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run path preparation using thread to reduce time\n",
    "def _run_thread(thread_id, thread_items, result):\n",
    "    for item_id in (thread_items):\n",
    "        result += _generate_path_from_entity_to_all_others(item_id, keep_relation_ratio=0.5,\n",
    "                                                           max_relation_num=MAX_RELATION_NUM, max_entity_per_relation=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## >> Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reformat_user_path(user_paths):\n",
    "\n",
    "    new_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for path in user_paths:\n",
    "        e1, r1, e2, r2, e3, r3, e4 = path.strip().split()\n",
    "\n",
    "        t1 = entity_type_to_id[get_type_from_entity_id(e1)]\n",
    "        t2 = entity_type_to_id[get_type_from_entity_id(e2)]\n",
    "        t3 = entity_type_to_id[get_type_from_entity_id(e3)]\n",
    "        t4 = entity_type_to_id[get_type_from_entity_id(e4)]\n",
    "\n",
    "        r4 = REL_ID_END\n",
    "\n",
    "        entity_rated = kg_path[e1][REL_ID_GIVEN_GOOD_RATING]\n",
    "        label = 1 if e4 in entity_rated else 0\n",
    "\n",
    "        new_paths.append([\n",
    "            [e1, t1, r1],\n",
    "            [e2, t2, r2],\n",
    "            [e3, t3, r3],\n",
    "            [e4, t4, r4],\n",
    "        ])\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(new_paths).astype('int'), np.array(labels).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_k_prediction(X_test, y_pred, k=10, get_best=True, max_pooling_size=-1):\n",
    "    \"\"\"\n",
    "    max_pooling_size -1 means without pooling\n",
    "    \"\"\"\n",
    "    if max_pooling_size > 0:\n",
    "        return _get_top_k_items_with_score_pooling(X_test, y_pred, k=10, max_pooling_size=max_pooling_size, get_best=get_best)\n",
    "    else:\n",
    "        return _get_top_k_items_without_score_pooling(X_test, y_pred, k=10, get_best=get_best)\n",
    "\n",
    "def _get_top_k_items_without_score_pooling(X_test, y_pred, k=10, get_best=True):\n",
    "    \"\"\"\n",
    "    Get the top-k items from X_test based on y_pred scores, \n",
    "    pick all path in sorted X_test until the amount of unique items is equal to k\n",
    "    \"\"\"\n",
    "    choosen_paths = []\n",
    "    choosen_items = set()\n",
    "\n",
    "    path_scores = sorted(zip(X_test, y_pred), key=lambda x: x[1], reverse=get_best)\n",
    "    for path, score in path_scores:\n",
    "        choosen_paths.append((path, score))\n",
    "        choosen_items.add(path[3][0])  # Add the last item\n",
    "\n",
    "        if len(choosen_items) >= k:\n",
    "            break\n",
    "\n",
    "    return choosen_paths, choosen_items\n",
    "\n",
    "def _get_top_k_items_with_score_pooling(X_test, y_pred, k=10, max_pooling_size=5, get_best=True):\n",
    "    \"\"\"\n",
    "    Get the top-k items from X_test based on averaged y_pred scores,\n",
    "    pick 'max_pooling_size' paths for each item, rank item based on average score, pick top k items.\n",
    "    \"\"\"\n",
    "    paths_group_by_items = {}\n",
    "    score_group_by_items = {}\n",
    "\n",
    "    path_scores = sorted(zip(X_test, y_pred), key=lambda x: x[1], reverse=get_best)\n",
    "    for path, score in path_scores:\n",
    "\n",
    "        ending_item = path[3][0]  # The last item before END RELATION\n",
    "\n",
    "        if ending_item not in paths_group_by_items:\n",
    "            paths_group_by_items[ending_item] = []\n",
    "            score_group_by_items[ending_item] = []\n",
    "\n",
    "        # Pool the paths and score\n",
    "        if len(paths_group_by_items[ending_item]) < max_pooling_size:\n",
    "            paths_group_by_items[ending_item].append((path, score))\n",
    "            score_group_by_items[ending_item].append(score)\n",
    "\n",
    "    # Calculate average\n",
    "    for item in score_group_by_items:\n",
    "        score_group_by_items[item] = sum(score_group_by_items[item]) / len(score_group_by_items[item])\n",
    "\n",
    "    # Sort pooled result\n",
    "    sorted_average_score = sorted(score_group_by_items.items(), key=lambda kv: kv[1], reverse=get_best)\n",
    "    choosen_items = {key for key, v in sorted_average_score[:k]}\n",
    "\n",
    "    # Filter top-k items with highest average score\n",
    "    choosen_paths = []\n",
    "    for item_id in choosen_items:\n",
    "        choosen_paths += paths_group_by_items[item_id]\n",
    "\n",
    "    return choosen_paths, choosen_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestion(user_id, k=10, max_pooling_size=-1):\n",
    "\n",
    "    user_paths = _generate_all_path_from_user(user_id, max_seed_num=MAX_SEED_NUM, max_seed_ratio=0.3)\n",
    "    X_test, _ = _reformat_user_path(user_paths)\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=2048, verbose=1)\n",
    "\n",
    "    top_paths, top_choosen_items = _get_k_prediction(X_test, y_pred, k=10, get_best=True, max_pooling_size=max_pooling_size)\n",
    "    worst_path, worst_choosen_items = _get_k_prediction(X_test, y_pred, k=10, get_best=False, max_pooling_size=max_pooling_size)\n",
    "\n",
    "    return top_paths, top_choosen_items, worst_path, worst_choosen_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_truth(user_id):\n",
    "    return set(kg_path[user_id][REL_ID_GIVEN_GOOD_RATING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_precision(pred, truth, k=10):\n",
    "\n",
    "    # Make sure same type\n",
    "    pred = {str(x) for x in pred}\n",
    "    truth = {str(x) for x in truth}\n",
    "\n",
    "    intersect = pred.intersection(truth)\n",
    "\n",
    "    len_intersect = len(intersect)\n",
    "    len_truth = len(truth) if 0 < len(truth) <= k else k\n",
    "\n",
    "    return intersect, len_intersect / len_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reasoning_paths(paths, truth_items=None):\n",
    "    reasoning_paths = []\n",
    "    for i in range(0, len(paths)):\n",
    "        user_path = paths[i]\n",
    "        user_truth = truth_items[i]\n",
    "\n",
    "        for path in user_path:\n",
    "\n",
    "            score = path[1]\n",
    "            reason_path = [str(score)]\n",
    "\n",
    "            for sequence in path[0]:\n",
    "                entity, _, relation = sequence\n",
    "                e = get_entity_name(str(entity))\n",
    "                r = get_entity_name(str(relation))\n",
    "\n",
    "                reason_path.append(e)\n",
    "                reason_path.append(r)\n",
    "\n",
    "                if str(relation) == REL_ID_END:\n",
    "                    watched = 'watched' if str(entity) in user_truth else \"nope\"\n",
    "                    reason_path.append(watched)\n",
    "\n",
    "            reason = \" -> \".join(reason_path)\n",
    "            reasoning_paths.append(reason)\n",
    "    return reasoning_paths\n",
    "\n",
    "\n",
    "def get_reasoning_paths_df(paths, truth_items=None):\n",
    "    reasoning_paths = []\n",
    "    for i in range(0, len(paths)):\n",
    "        user_path = paths[i]\n",
    "        user_truth = truth_items[i]\n",
    "\n",
    "        for path in user_path:\n",
    "\n",
    "            score = path[1]\n",
    "            reason_path = [str(score)]\n",
    "\n",
    "            for sequence in path[0]:\n",
    "                entity, _, relation = sequence\n",
    "                e = get_entity_name(str(entity))\n",
    "                r = get_entity_name(str(relation))\n",
    "\n",
    "                reason_path.append(e)\n",
    "                reason_path.append(r)\n",
    "\n",
    "                if str(relation) == REL_ID_END:\n",
    "                    watched = 'watched' if str(entity) in user_truth else \"nope\"\n",
    "                    reason_path.append(watched)\n",
    "\n",
    "            reasoning_paths.append(reason_path)\n",
    "    return pd.DataFrame(reasoning_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compare_prediction_truth(predictions, truths):\n",
    "\n",
    "    predictions = [get_entity_name(str(p)) for p in predictions]\n",
    "    truths = [get_entity_name(str(t)) for t in truths]\n",
    "\n",
    "    print(\"Predictions : \")\n",
    "    for p in sorted(predictions):\n",
    "        is_watched = \"watched\" if str(p) in truths else \"nope\"\n",
    "        print(\"{} > {}\".format(p, is_watched))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Truth : \")\n",
    "    for t in sorted(truths):\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240167/240167 [==============================] - 1s 6us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [01:54<55:32, 114.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72790/72790 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [02:12<40:01, 85.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174742/174742 [==============================] - 1s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [03:45<39:31, 87.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213727/213727 [==============================] - 1s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [05:12<37:56, 87.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99703/99703 [==============================] - 0s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [06:16<33:34, 80.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432914/432914 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [10:21<52:00, 130.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653660/653660 [==============================] - 2s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [17:38<1:25:07, 222.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115376/115376 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [18:16<1:01:10, 166.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895761/895761 [==============================] - 2s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [24:57<1:22:58, 237.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154188/154188 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [25:43<59:56, 179.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203636/203636 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [27:28<49:49, 157.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239949/239949 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [28:29<38:30, 128.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84634/84634 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [28:53<27:30, 97.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104266/104266 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [29:26<20:46, 77.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71162/71162 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [30:15<17:17, 69.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203753/203753 [==============================] - 1s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [32:26<20:27, 87.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112272/112272 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [33:12<16:17, 75.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221329/221329 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [35:28<18:41, 93.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400216/400216 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [37:36<19:02, 103.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158615/158615 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [38:08<13:42, 82.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169468/1169468 [==============================] - 3s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [46:22<30:50, 205.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131997/1131997 [==============================] - 3s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [52:46<34:34, 259.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131024/131024 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [53:32<22:45, 195.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329607/1329607 [==============================] - 4s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [1:00:25<26:03, 260.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304505/304505 [==============================] - 1s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [1:02:06<17:42, 212.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80931/80931 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [1:02:40<10:36, 159.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163985/163985 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [1:04:25<07:08, 142.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86171/86171 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [1:05:56<04:14, 127.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80797/80797 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [1:06:40<01:42, 102.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125801/125801 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [1:07:51<00:00, 93.09s/it] \n"
     ]
    }
   ],
   "source": [
    "k_suggestions = 10\n",
    "n_users = 30\n",
    "\n",
    "sample_user = np.random.randint(500001, 630000, n_users)\n",
    "sample_user = [str(x) for x in sample_user]\n",
    "\n",
    "top_paths = []\n",
    "top_items = []\n",
    "worst_paths = []\n",
    "worst_items = []\n",
    "\n",
    "truth_items = []\n",
    "\n",
    "n_paths = []\n",
    "intersects = []\n",
    "scores = []\n",
    "\n",
    "all_intersect = None\n",
    "all_union = None\n",
    "\n",
    "for user in tqdm(sample_user):\n",
    "    top_suggested_path, top_suggested_items, worst_suggested_path, worst_suggested_items = get_suggestion(user, k=k_suggestions, max_pooling_size=3)\n",
    "    top_truth_items = get_top_truth(user)\n",
    "\n",
    "    intersect, score = check_precision(top_suggested_items, top_truth_items)\n",
    "\n",
    "    top_paths.append(top_suggested_path)\n",
    "    top_items.append(top_suggested_items)\n",
    "\n",
    "    worst_paths.append(worst_suggested_path)\n",
    "    worst_items.append(worst_suggested_items)\n",
    "\n",
    "    intersects.append(intersect)\n",
    "    truth_items.append(top_truth_items)\n",
    "\n",
    "    n_paths.append(len(top_suggested_path))\n",
    "    scores.append(score)\n",
    "\n",
    "    if all_intersect is None:\n",
    "        all_intersect = top_suggested_items\n",
    "    else:\n",
    "        all_intersect = all_intersect.intersection(top_suggested_items)\n",
    "\n",
    "    if all_union is None:\n",
    "        all_union = top_suggested_items\n",
    "    else:\n",
    "        all_union = all_union.union(top_suggested_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec@k score: 0.25111111111111106\n",
      "\n",
      "intersect\n",
      "{10659} 1\n",
      "\n",
      "union\n",
      "{8962, 10371, 911, 11536, 1169, 1170, 1168, 9104, 14868, 534, 2073, 11677, 546, 10659, 676, 1321, 11435, 10796, 5548, 1457, 6834, 15154, 5939, 693, 4791, 9399, 5441, 5058, 13122, 12355, 14025, 2506, 3401, 10825, 11212, 4687, 7631, 3538, 2899, 4820, 90, 10842, 2525, 8672, 14048, 11494, 3815, 4071, 4473, 5738, 8811, 491, 1774, 12016, 5619, 11892, 9846, 5497, 2298, 5629, 2942} 61\n",
      "\n",
      "distinct rate\n",
      "0.20333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Prec@k score:\", np.average(scores))\n",
    "# print(\"top_suggested_items:\", top_suggested_items)\n",
    "# print(\"truth_items:\", truth_items)\n",
    "\n",
    "print(\"\\nintersect\")\n",
    "print(all_intersect, len(all_intersect))\n",
    "print(\"\\nunion\")\n",
    "print(all_union, len(all_union))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(all_union)) / (n_users * k_suggestions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions : \n",
      "http://dbpedia.org/resource/Back_to_the_Future_Part_III > nope\n",
      "http://dbpedia.org/resource/Being_John_Malkovich > nope\n",
      "http://dbpedia.org/resource/Fargo_(film) > nope\n",
      "http://dbpedia.org/resource/Forrest_Gump > watched\n",
      "http://dbpedia.org/resource/Good_Will_Hunting > watched\n",
      "http://dbpedia.org/resource/Goodfellas > nope\n",
      "http://dbpedia.org/resource/Pulp_Fiction > nope\n",
      "http://dbpedia.org/resource/Saving_Private_Ryan > nope\n",
      "http://dbpedia.org/resource/Schindler's_List > watched\n",
      "http://dbpedia.org/resource/Toy_Story > nope\n",
      "\n",
      "\n",
      "Truth : \n",
      "http://dbpedia.org/resource/28_Days_(film)\n",
      "http://dbpedia.org/resource/Adventures_in_Babysitting_(2016_film)\n",
      "http://dbpedia.org/resource/Apollo_13_(film)\n",
      "http://dbpedia.org/resource/As_Good_as_It_Gets\n",
      "http://dbpedia.org/resource/Big_Trouble_in_Little_China\n",
      "http://dbpedia.org/resource/Boys_on_the_Side\n",
      "http://dbpedia.org/resource/Braveheart_(1925_film)\n",
      "http://dbpedia.org/resource/Cast_Away\n",
      "http://dbpedia.org/resource/Cinderella_Man\n",
      "http://dbpedia.org/resource/City_Slickers\n",
      "http://dbpedia.org/resource/City_of_God_(2002_film)\n",
      "http://dbpedia.org/resource/Clue_(film)\n",
      "http://dbpedia.org/resource/Eternal_Sunshine_of_the_Spotless_Mind\n",
      "http://dbpedia.org/resource/Fear_and_Loathing_in_Las_Vegas_(film)\n",
      "http://dbpedia.org/resource/Fight_Club\n",
      "http://dbpedia.org/resource/Finding_Nemo\n",
      "http://dbpedia.org/resource/Forrest_Gump\n",
      "http://dbpedia.org/resource/Gattaca\n",
      "http://dbpedia.org/resource/Gladiator_(2000_film)\n",
      "http://dbpedia.org/resource/Good_Will_Hunting\n",
      "http://dbpedia.org/resource/Kiss_Kiss_Bang_Bang\n",
      "http://dbpedia.org/resource/Mad_Max_Beyond_Thunderdome\n",
      "http://dbpedia.org/resource/Ocean's_Eleven\n",
      "http://dbpedia.org/resource/Of_Mice_and_Men_(1939_film)\n",
      "http://dbpedia.org/resource/One_Flew_Over_the_Cuckoo's_Nest_(film)\n",
      "http://dbpedia.org/resource/Philadelphia_(film)\n",
      "http://dbpedia.org/resource/Point_Break\n",
      "http://dbpedia.org/resource/Rounders_(film)\n",
      "http://dbpedia.org/resource/Schindler's_List\n",
      "http://dbpedia.org/resource/Seven_(1995_film)\n",
      "http://dbpedia.org/resource/Shrek\n",
      "http://dbpedia.org/resource/Shutter_Island_(film)\n",
      "http://dbpedia.org/resource/When_Harry_Met_Sally...\n"
     ]
    }
   ],
   "source": [
    "sample_user_idx = 0\n",
    "get_reasoning_paths([top_paths[sample_user_idx]], [truth_items[sample_user_idx]])\n",
    "compare_prediction_truth(top_items[sample_user_idx], truth_items[sample_user_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
